# PostgreSQL 고성능 트랜잭션 최적화 가이드

## 목차
1. [소개](#소개)
2. [고성능 쓰기 트랜잭션 최적화](#고성능-쓰기-트랜잭션-최적화)
3. [고성능 읽기 트랜잭션 최적화](#고성능-읽기-트랜잭션-최적화)
4. [읽기/쓰기 혼합 워크로드 최적화](#읽기쓰기-혼합-워크로드-최적화)
5. [실전 시나리오](#실전-시나리오-및-벤치마크)
6. [성능 측정 및 벤치마킹](#성능-측정-및-벤치마킹)
7. [체크리스트](#체크리스트-및-빠른-참조)
8. [FAQ](#faq)

---

## 소개

### 성능의 정의

데이터베이스 성능은 여러 지표로 측정됩니다:

- **TPS (Transactions Per Second)**: 초당 처리 가능한 트랜잭션 수
  - 쓰기 성능의 핵심 지표
  - 예: 10,000 TPS = 초당 1만 건의 INSERT/UPDATE/DELETE 처리

- **QPS (Queries Per Second)**: 초당 처리 가능한 쿼리 수
  - 읽기 성능의 핵심 지표
  - 예: 50,000 QPS = 초당 5만 건의 SELECT 처리

- **지연시간 (Latency)**: 단일 작업이 완료되는 데 걸리는 시간
  - 평균 (Average): 전체 평균
  - P50 (Median): 중간값
  - P95/P99: 상위 5%/1%의 느린 요청 (테일 레이턴시)
  - 예: P95 < 100ms = 95%의 요청이 100ms 이내에 완료

- **처리량 (Throughput)**: 단위 시간당 처리된 데이터양
  - 예: 1GB/s, 100MB/s

### 트레이드오프의 이해

**쓰기 최적화 vs 읽기 최적화는 종종 상충됩니다:**

| 최적화 기법 | 쓰기 성능 | 읽기 성능 |
|----------|---------|---------|
| **인덱스 추가** | ❌ 저하 (각 INSERT마다 인덱스 업데이트) | ✅ 향상 (빠른 검색) |
| **낮은 격리 수준 (Read Committed)** | ✅ 향상 (동시성↑) | ⚠️ 일관성 문제 가능 |
| **synchronous_commit = off** | ✅ 향상 (2-5배) | - 영향 없음 |
| **Materialized View** | ❌ 저하 (추가 쓰기 필요) | ✅ 향상 (사전 계산) |
| **파티셔닝** | ✅ 향상 (집중된 쓰기) | ✅ 향상 (파티션 프루닝) |

### PostgreSQL MVCC 특성이 성능에 미치는 영향

PostgreSQL의 **MVCC (Multi-Version Concurrency Control)** 는 고성능 동시성을 가능하게 하지만, 트레이드오프가 있습니다:

✅ **장점**:
- 읽기는 쓰기를 차단하지 않음
- 쓰기는 읽기를 차단하지 않음
- 높은 동시성 달성 가능

⚠️ **단점**:
- UPDATE/DELETE는 새 튜플 버전 생성 → Dead tuple 발생
- Dead tuple은 VACUUM으로 정리 필요
- 인덱스도 튜플 버전 유지 → 추가 공간 소비
- 긴 트랜잭션은 VACUUM 방해 → Table bloat

**결론**: 성능 최적화 시 VACUUM과 bloat 관리가 필수!

### 문서 사용 가이드

- **쓰기 집약적 워크로드** → [섹션 2](#고성능-쓰기-트랜잭션-최적화) 참고
- **읽기 집약적 워크로드** → [섹션 3](#고성능-읽기-트랜잭션-최적화) 참고
- **혼합 워크로드** → [섹션 4](#읽기쓰기-혼합-워크로드-최적화) 참고
- **실전 예시 필요** → [섹션 5](#실전-시나리오-및-벤치마크) 참고

---

## 고성능 쓰기 트랜잭션 최적화

### 1. 격리 수준 선택

#### Read Committed 사용 (기본값)

**왜?**
- 각 쿼리마다 새로운 스냅샷 생성 → 스냅샷 오버헤드 최소
- 스냅샷이 짧은 시간만 유지 → VACUUM이 빠르게 dead tuple 정리 가능
- 높은 동시성 → 여러 트랜잭션이 서로 차단하지 않음

**트레이드오프**:
- Non-repeatable read 발생 가능
- 애플리케이션에서 일관성 보장 필요

**적합한 경우**:
- 로그 수집 시스템
- 센서 데이터 저장
- 이벤트 스트리밍
- 분석 데이터 적재

**예시**:
```sql
-- 기본값이므로 별도 설정 불필요
BEGIN;
INSERT INTO logs (timestamp, level, message)
VALUES (NOW(), 'INFO', 'User login');
COMMIT;
```

#### Serializable 피하기

**왜?**
- SSI (Serializable Snapshot Isolation) 체크 오버헤드
- 직렬화 충돌 시 트랜잭션 재시도 → 처리량 감소
- 쓰기 집약적 워크로드에서는 충돌 가능성 높음

**벤치마크 비교** (동일한 워크로드):
```
Read Committed:    10,000 TPS
Repeatable Read:    8,500 TPS
Serializable:       6,000 TPS (+ 5-15% 재시도율)
```

---

### 2. 배치 처리 (Batch Processing)

#### COPY 명령 사용

**왜?**
- 파싱/플래닝 오버헤드 제거: 단일 명령으로 대량 데이터 처리
- WAL 생성 최소화: 효율적인 벌크 로딩
- 트랜잭션 오버헤드 감소

**벤치마크**: COPY가 개별 INSERT보다 **10-50배 빠름**

**COPY FROM STDIN 예시** (Python):
```python
import psycopg2
from io import StringIO

conn = psycopg2.connect("dbname=mydb")
cur = conn.cursor()

# 대량 데이터 준비
data = StringIO()
for i in range(100000):
    data.write(f"{i}\tvalue_{i}\n")
data.seek(0)

# COPY 실행
cur.copy_from(data, 'my_table', columns=('id', 'value'))
conn.commit()

# 결과: 100,000 rows in < 1초
```

**COPY FROM CSV 예시**:
```sql
COPY logs (timestamp, level, message)
FROM '/path/to/logs.csv'
WITH (FORMAT csv, HEADER true);
```

#### 다중 행 INSERT

**왜?**
- 네트워크 왕복 감소: 1번의 통신으로 여러 행 삽입
- 파싱/실행 계획 오버헤드 감소: 쿼리 1번만 파싱

**예시**:
```sql
-- 나쁜 예: 개별 INSERT
INSERT INTO products (name, price) VALUES ('Product A', 100);
INSERT INTO products (name, price) VALUES ('Product B', 200);
INSERT INTO products (name, price) VALUES ('Product C', 300);
-- 3번의 파싱, 3번의 왕복

-- 좋은 예: 다중 행 INSERT
INSERT INTO products (name, price) VALUES
  ('Product A', 100),
  ('Product B', 200),
  ('Product C', 300);
-- 1번의 파싱, 1번의 왕복
```

**Python 예시** (psycopg2):
```python
# execute_values로 최적화
from psycopg2.extras import execute_values

data = [
    ('Product A', 100),
    ('Product B', 200),
    ('Product C', 300),
]

execute_values(
    cur,
    "INSERT INTO products (name, price) VALUES %s",
    data
)
```

#### 트랜잭션 배치

**왜?**
- 커밋 오버헤드 감소: WAL fsync 횟수 감소
- 처리량 향상: 여러 작은 트랜잭션보다 큰 트랜잭션 하나가 효율적

**주의**: 너무 크면 잠금 시간 증가 및 VACUUM 지연

**최적 배치 크기**: 일반적으로 **1,000 ~ 10,000 rows**

```sql
BEGIN;

INSERT INTO events VALUES (1, 'event1');
INSERT INTO events VALUES (2, 'event2');
-- ... 1000개의 INSERT
INSERT INTO events VALUES (1000, 'event1000');

COMMIT;  -- 1번의 커밋으로 1000개 처리
```

---

### 3. 인덱스 전략

#### 쓰기 시 인덱스 오버헤드

**문제**:
- 각 INSERT/UPDATE마다 **모든 인덱스도 업데이트**
- 인덱스 5개 → 쓰기 작업 6배 (데이터 1 + 인덱스 5)

**벤치마크**:
```
인덱스 0개: 10,000 TPS
인덱스 1개:  8,000 TPS (-20%)
인덱스 3개:  6,000 TPS (-40%)
인덱스 5개:  5,000 TPS (-50%)
```

#### 최적화 전략 1: 필수 인덱스만 유지

**원칙**:
- Primary Key는 필수
- 자주 쿼리되는 컬럼에만 인덱스
- "혹시 모르니까" 인덱스는 제거

**인덱스 사용률 확인**:
```sql
SELECT
  schemaname,
  tablename,
  indexname,
  idx_scan AS index_scans,
  pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
FROM pg_stat_user_indexes
WHERE idx_scan = 0  -- 사용되지 않는 인덱스
  AND indexrelname NOT LIKE '%_pkey'  -- PK 제외
ORDER BY pg_relation_size(indexrelid) DESC;
```

#### 최적화 전략 2: 배치 로드 시 인덱스 재생성

**전략**: DROP → COPY → CREATE

```sql
-- 1. 인덱스 제거
DROP INDEX idx_logs_timestamp;
DROP INDEX idx_logs_level;

-- 2. 대량 데이터 로드
COPY logs FROM '/data/logs.csv' WITH (FORMAT csv);

-- 3. 인덱스 재생성 (CONCURRENTLY로 테이블 잠금 방지)
CREATE INDEX CONCURRENTLY idx_logs_timestamp ON logs(timestamp);
CREATE INDEX CONCURRENTLY idx_logs_level ON logs(level);
```

**벤치마크**:
- 인덱스 유지하면서 COPY: 10분
- 인덱스 DROP → COPY → CREATE: 3분 (3배 빠름)

#### 최적화 전략 3: 부분 인덱스 (Partial Index)

**왜?**
- 인덱스 크기 감소 → 쓰기 오버헤드 감소
- 자주 쿼리되는 데이터만 인덱싱

**예시**:
```sql
-- 나쁜 예: 전체 인덱스
CREATE INDEX idx_orders_status ON orders(status);
-- 모든 상태 (completed, pending, cancelled 등) 인덱싱

-- 좋은 예: 부분 인덱스
CREATE INDEX idx_orders_pending ON orders(created_at)
WHERE status = 'pending';
-- 'pending' 상태만 인덱싱 (90%는 'completed'라고 가정)
```

**결과**: 인덱스 크기 90% 감소 → 쓰기 성능 향상

---

### 4. VACUUM 및 Autovacuum 튜닝

#### 쓰기 집약적 워크로드의 문제

**문제**:
- 빠른 INSERT/UPDATE/DELETE → Dead tuple 빠른 증가
- Dead tuple이 쌓이면 → Table bloat → 읽기/쓰기 모두 느려짐
- 기본 autovacuum 설정은 쓰기 집약적 테이블에 부족

#### 공격적인 Autovacuum 설정

**목표**: Dead tuple을 빠르게 정리하여 bloat 방지

```sql
ALTER TABLE heavy_write_table SET (
  -- 테이블의 5%만 변경되어도 VACUUM 실행 (기본 20%)
  autovacuum_vacuum_scale_factor = 0.05,

  -- 최소 1000 rows 변경되면 VACUUM (기본 50)
  autovacuum_vacuum_threshold = 1000,

  -- ANALYZE도 더 자주 실행
  autovacuum_analyze_scale_factor = 0.05,
  autovacuum_analyze_threshold = 500
);
```

**이유**:
- 빈번한 VACUUM → Dead tuple이 쌓이기 전에 정리
- Bloat 방지 → 테이블 크기 유지 → 성능 유지

**전역 설정** (postgresql.conf):
```sql
autovacuum = on
autovacuum_max_workers = 3         -- 기본값, 필요 시 증가
autovacuum_naptime = 10s          -- 10초마다 체크 (기본 1분)
autovacuum_vacuum_cost_limit = 400  -- 더 공격적 (기본 200)
```

#### HOT (Heap-Only Tuple) 최적화

**HOT란?**
- Heap-Only Tuple: UPDATE 시 인덱스를 업데이트하지 않고 같은 페이지 내에서만 튜플 업데이트

**Fill Factor 조정**:
```sql
-- 기본 fillfactor = 100 (페이지 100% 사용)
-- 70으로 설정 → 페이지의 30%는 여유 공간

ALTER TABLE frequently_updated_table SET (fillfactor = 70);

-- 기존 데이터에 적용
VACUUM FULL frequently_updated_table;
```

**이유**:
- 페이지 내 여유 공간 → UPDATE 시 같은 페이지에 새 버전 저장 가능
- HOT Update → 인덱스 업데이트 불필요 → UPDATE 성능 2-3배 향상

**트레이드오프**:
- 테이블 크기 30% 증가
- UPDATE가 많은 테이블에만 사용

---

### 5. WAL (Write-Ahead Log) 최적화

#### synchronous_commit 설정

**기본 동작** (`synchronous_commit = on`):
1. 트랜잭션 COMMIT
2. WAL을 디스크에 fsync (물리적 쓰기 완료 대기)
3. COMMIT 완료 응답

**문제**: fsync는 느림 (특히 HDD) → 지연시간 증가

**최적화**: `synchronous_commit = off`

```sql
-- 데이터베이스 전체 설정
ALTER SYSTEM SET synchronous_commit = off;
SELECT pg_reload_conf();

-- 또는 세션별 설정
SET synchronous_commit = off;

-- 또는 트랜잭션별 설정
BEGIN;
SET LOCAL synchronous_commit = off;
INSERT INTO logs ...;
COMMIT;
```

**효과**:
- WAL 쓰기를 백그라운드로 지연
- COMMIT이 즉시 반환 → **처리량 2-5배 향상**
- 지연시간 ms → μs

**트레이드오프**:
- 크래시 시 최근 트랜잭션 손실 가능 (최대 수 초)
- 데이터 **손실 허용 가능한 경우에만** 사용
  - ✅ 로그 수집, 메트릭 저장, 캐시 데이터
  - ❌ 금융 거래, 사용자 계정 정보

**대안**: `synchronous_commit = local`
- Replica로의 복제는 비동기
- 로컬 디스크에는 동기 쓰기
- Primary 크래시는 안전, Replica는 약간 지연 허용

#### WAL 버퍼 크기

```sql
-- postgresql.conf
wal_buffers = 16MB  -- 기본 -1 (shared_buffers의 1/32, max 16MB)
```

**왜?**
- WAL 쓰기를 버퍼링 → 디스크 I/O 감소
- 쓰기 집약적 워크로드에서 병목 가능

**권장값**:
- 일반적: 기본값 (16MB)
- 쓰기 매우 많음: 32MB ~ 64MB

---

### 6. 연결 및 트랜잭션 설정

#### 연결 풀링 필수

**문제**:
- PostgreSQL 연결 생성 비용이 큼 (프로세스 fork)
- 연결마다 메모리 할당 (수 MB)
- 1000 동시 연결 → 수 GB 메모리 소비

**해결책**: 연결 풀러 사용

**PgBouncer 설정**:
```ini
[databases]
mydb = host=localhost dbname=mydb

[pgbouncer]
pool_mode = transaction  # 쓰기 집약적에 적합
max_client_conn = 1000   # 애플리케이션 연결 수
default_pool_size = 20   # 실제 DB 연결 수
```

**효과**:
- 1000 앱 연결 → 20 DB 연결로 변환
- 연결 재사용 → 연결 생성 오버헤드 제거
- 메모리 절약

**Session vs Transaction 모드**:
| 모드 | 연결 재사용 시점 | 적합한 경우 |
|------|---------------|----------|
| Session | 클라이언트 연결 종료 시 | Prepared statements, 임시 테이블 사용 |
| Transaction | 트랜잭션 완료 시 | 쓰기 집약적, 짧은 트랜잭션 |

**쓰기 집약적 워크로드**: Transaction 모드 권장

#### Prepared Statements

**왜?**
- 쿼리 파싱/계획을 캐싱 → 반복 쿼리 성능 향상

**예시** (Python psycopg2):
```python
# Prepared statement 사용
cur.execute("PREPARE insert_log AS INSERT INTO logs (msg) VALUES ($1)")
cur.execute("EXECUTE insert_log (%s)", ("log message",))
```

**효과**: 반복적인 INSERT에서 10-20% 성능 향상

---

### 7. 하드웨어 및 스토리지

#### SSD 필수

**왜?**
- 쓰기 IOPS가 성능 병목
- WAL 쓰기는 순차 I/O이지만 fsync는 지연 발생

**성능 비교** (동일한 워크로드):
```
HDD 7200 RPM:    1,000 TPS
SATA SSD:       10,000 TPS (10배)
NVMe SSD:       25,000 TPS (25배)
```

#### WAL과 데이터 디렉토리 분리

**전략**: WAL을 별도의 빠른 디스크에 저장

```bash
# PostgreSQL 초기화 시
initdb -D /data/postgresql --waldir=/nvme/pg_wal

# 또는 기존 클러스터에서 심볼릭 링크
mv /data/postgresql/pg_wal /nvme/pg_wal
ln -s /nvme/pg_wal /data/postgresql/pg_wal
```

**이유**:
- WAL: 순차 쓰기 집약적
- 데이터: 랜덤 읽기/쓰기 혼합
- 분리 → I/O 경합 감소 → 성능 향상 10-30%

---

### 8. 테이블 파티셔닝

#### 시간 기반 파티셔닝 (로그, 시계열 데이터)

**전략**:
```sql
-- 파티션 테이블 생성
CREATE TABLE logs (
  id BIGSERIAL,
  created_at TIMESTAMPTZ NOT NULL,
  level VARCHAR(10),
  message TEXT
) PARTITION BY RANGE (created_at);

-- 월별 파티션
CREATE TABLE logs_2024_01 PARTITION OF logs
  FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE logs_2024_02 PARTITION OF logs
  FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');
```

**쓰기 성능 향상 이유**:
1. **집중된 쓰기**: 최신 파티션에만 쓰기 → 해당 파티션만 hot
2. **VACUUM 효율성**: 오래된 파티션은 VACUUM 불필요 → 리소스 절약
3. **인덱스 크기 감소**: 파티션별 인덱스 → 작은 인덱스 → 빠른 업데이트

**오래된 파티션 처리**:
```sql
-- 오래된 파티션을 읽기 전용으로 압축
ALTER TABLE logs_2023_12 SET (fillfactor = 100);
VACUUM FULL logs_2023_12;

-- 또는 완전히 제거
DROP TABLE logs_2023_01;
```

---

## 고성능 읽기 트랜잭션 최적화

### 1. 격리 수준 선택

#### Read Committed (기본값)

**언제?**
- 대부분의 읽기 워크로드에 적합
- 단순 조회, 목록 조회, 검색

**장점**:
- 스냅샷 오버헤드 최소
- 최신 커밋된 데이터 보장

```sql
BEGIN;
-- 기본값이므로 별도 설정 불필요
SELECT * FROM products WHERE category = 'electronics';
COMMIT;
```

#### Repeatable Read

**언제?**
- 복잡한 분석 쿼리
- 여러 단계의 집계가 필요한 보고서
- 트랜잭션 내에서 일관된 데이터 필요

**장점**:
- 트랜잭션 전체에서 일관된 스냅샷
- 정확한 분석 결과 보장

```sql
BEGIN;
SET TRANSACTION ISOLATION LEVEL REPEATABLE READ;

-- 여러 쿼리가 동일한 스냅샷 사용
SELECT SUM(amount) FROM orders WHERE date >= '2024-01-01';
SELECT AVG(amount) FROM orders WHERE date >= '2024-01-01';
SELECT COUNT(*) FROM orders WHERE date >= '2024-01-01';

COMMIT;
```

#### 읽기 전용 트랜잭션 표시

```sql
BEGIN;
SET TRANSACTION READ ONLY;  -- 또는 ISOLATION LEVEL ... READ ONLY

SELECT * FROM large_table WHERE ...;

COMMIT;
```

**이유**:
- PostgreSQL에 "읽기만 함" 힌트 제공
- 불필요한 잠금 회피
- 특정 최적화 활성화 (예: 병렬 쿼리)

---

### 2. 인덱스 전략

#### 적절한 인덱스 타입 선택

| 인덱스 타입 | 적합한 경우 | 예시 |
|-----------|----------|-----|
| **B-tree** (기본) | 범위 검색, 정렬, 동등 비교 | `id = 5`, `created_at > '2024-01-01'` |
| **Hash** | 동등 비교만 (=) | `user_id = 123` (PostgreSQL 10+) |
| **GIN** | 배열, JSONB, 전문 검색 | `tags @> '{postgres}'`, `data @> '{"key":"value"}'` |
| **GiST** | 지리 데이터, 범위 타입 | PostGIS, `tsrange`, `int4range` |
| **BRIN** | 대용량 시계열, 자연 정렬 | `created_at` (시간순 삽입) |

**BRIN 예시** (초대용량 로그 테이블):
```sql
-- B-tree 인덱스: 10GB
CREATE INDEX idx_logs_created_btree ON logs(created_at);

-- BRIN 인덱스: 10MB (1000배 작음!)
CREATE INDEX idx_logs_created_brin ON logs USING brin(created_at);

-- BRIN은 범위 검색에 효율적 (데이터가 물리적으로 정렬된 경우)
SELECT * FROM logs WHERE created_at > NOW() - INTERVAL '1 day';
```

#### 인덱스 커버링 스캔

**개념**: 인덱스만으로 쿼리 완료 (테이블 접근 불필요)

```sql
-- 기존 인덱스
CREATE INDEX idx_orders_user ON orders(user_id);

-- 쿼리
SELECT user_id, order_date, total
FROM orders
WHERE user_id = 123;
-- 문제: user_id는 인덱스에 있지만, order_date와 total은 테이블 접근 필요

-- 개선: 커버링 인덱스 (INCLUDE)
CREATE INDEX idx_orders_user_cover ON orders(user_id)
  INCLUDE (order_date, total);

-- 이제 테이블 접근 없이 인덱스만으로 완료 → 2-5배 빠름
```

**효과**:
- 테이블 I/O 제거
- 특히 큰 테이블에서 효과적

#### 복합 인덱스 순서

**원칙**: 선택도가 높은(고유값이 많은) 컬럼을 앞에

```sql
-- 나쁜 예
CREATE INDEX idx_bad ON orders(status, user_id);
-- status는 3-5가지 값만 (pending, completed, cancelled)
-- user_id는 수십만 값

-- 좋은 예
CREATE INDEX idx_good ON orders(user_id, status);
-- 더 선택적인 user_id를 앞에
```

**쿼리**:
```sql
-- idx_good을 효율적으로 사용
SELECT * FROM orders WHERE user_id = 123 AND status = 'pending';

-- idx_good을 부분적으로 사용 (user_id만)
SELECT * FROM orders WHERE user_id = 123;

-- idx_bad은 status만으로는 비효율적
```

#### 인덱스 통계 최신화

```sql
-- 테이블 통계 업데이트
ANALYZE orders;

-- 전체 데이터베이스
ANALYZE;

-- 자동화 (autovacuum이 자동으로 실행)
-- postgresql.conf
autovacuum = on
```

**왜 중요?**
- 쿼리 플래너가 통계 기반으로 실행 계획 선택
- 오래된 통계 → 잘못된 계획 → 느린 쿼리

---

### 3. 쿼리 최적화

#### EXPLAIN ANALYZE 활용

```sql
EXPLAIN ANALYZE
SELECT o.order_id, u.name, SUM(oi.amount)
FROM orders o
JOIN users u ON o.user_id = u.id
JOIN order_items oi ON o.order_id = oi.order_id
WHERE o.created_at > NOW() - INTERVAL '30 days'
GROUP BY o.order_id, u.name;
```

**분석 포인트**:
1. **Seq Scan vs Index Scan**: Seq Scan이 나오면 인덱스 필요
2. **실제 시간**: `actual time=...` 확인
3. **Rows**: 예상 rows vs 실제 rows 비교 (차이 크면 ANALYZE 필요)
4. **Buffers**: 디스크 I/O vs 캐시 히트

**예시 출력**:
```
HashAggregate  (actual time=45.123..45.234 rows=1523)
  ->  Hash Join  (actual time=2.345..42.123 rows=15230)
        Hash Cond: (o.user_id = u.id)
        ->  Index Scan using idx_orders_created on orders o
            (actual time=0.123..15.234 rows=15230)
              Index Cond: (created_at > '2023-12-18')
        ->  Hash (actual time=2.123..2.123 rows=5000)
              ->  Seq Scan on users u (actual time=0.012..1.234 rows=5000)
```

#### JOIN 최적화

**원칙**:
1. **작은 테이블을 먼저 JOIN** (드라이빙 테이블)
2. **JOIN 조건에 인덱스** 필수
3. **INNER JOIN 선호** (옵티마이저가 순서 재배치 가능)

```sql
-- 좋은 예
SELECT *
FROM small_table s
INNER JOIN large_table l ON s.id = l.small_id
WHERE s.category = 'active';

-- 나쁜 예: LEFT JOIN은 순서 고정
SELECT *
FROM large_table l
LEFT JOIN small_table s ON l.small_id = s.id;
```

**JOIN 조건 인덱스**:
```sql
-- JOIN 조건에 인덱스
CREATE INDEX idx_orders_user_id ON orders(user_id);
CREATE INDEX idx_order_items_order_id ON order_items(order_id);
```

#### Materialized View

**언제?**
- 복잡한 집계 쿼리
- 자주 조회되지만 데이터 변경은 드문 경우
- 실시간성이 필수가 아닌 보고서

**예시**:
```sql
-- Materialized View 생성
CREATE MATERIALIZED VIEW sales_summary AS
SELECT
  DATE_TRUNC('day', created_at) AS day,
  user_id,
  COUNT(*) AS order_count,
  SUM(total) AS total_sales
FROM orders
GROUP BY DATE_TRUNC('day', created_at), user_id;

-- 인덱스 추가
CREATE INDEX idx_sales_summary_day ON sales_summary(day);

-- 쿼리 (원본보다 100배 빠름)
SELECT * FROM sales_summary WHERE day >= '2024-01-01';

-- 데이터 갱신 (정기적으로 실행)
REFRESH MATERIALIZED VIEW CONCURRENTLY sales_summary;
-- CONCURRENTLY: 쿼리 차단 없이 갱신
```

**트레이드오프**:
- 사전 계산 비용 (REFRESH 시간)
- 스토리지 사용량 증가
- 약간 오래된 데이터 (마지막 REFRESH 시점)

---

### 4. 연결 풀링 및 캐싱

#### PgBouncer Transaction 모드

```ini
[pgbouncer]
pool_mode = transaction  # 읽기 집약적에 적합
max_client_conn = 5000   # 많은 동시 읽기 요청
default_pool_size = 50   # 실제 DB 연결
```

**효과**:
- 5000 동시 읽기 요청 → 50 DB 연결로 처리
- 연결 재사용 → 최대 처리량

#### 애플리케이션 레벨 캐싱

**Redis 캐싱 패턴**:
```python
import redis
import psycopg2

redis_client = redis.Redis()
db_conn = psycopg2.connect("dbname=mydb")

def get_user(user_id):
    # 1. Redis 캐시 확인
    cached = redis_client.get(f"user:{user_id}")
    if cached:
        return json.loads(cached)

    # 2. 캐시 미스 → DB 조회
    cur = db_conn.cursor()
    cur.execute("SELECT * FROM users WHERE id = %s", (user_id,))
    user = cur.fetchone()

    # 3. Redis에 캐싱 (TTL 1시간)
    redis_client.setex(f"user:{user_id}", 3600, json.dumps(user))

    return user
```

**효과**:
- 캐시 히트율 80% → DB 부하 80% 감소
- 응답 시간: 50ms → 1ms

#### PostgreSQL 공유 버퍼

```sql
-- postgresql.conf
shared_buffers = 8GB  -- 일반적으로 RAM의 25%

-- 또는 동적 설정
ALTER SYSTEM SET shared_buffers = '8GB';
-- 재시작 필요
```

**왜?**
- 자주 접근하는 페이지를 메모리에 유지
- 디스크 I/O 감소

**권장값**:
- RAM 32GB → shared_buffers = 8GB
- RAM 128GB → shared_buffers = 32GB (너무 크면 오히려 비효율)

---

### 5. 파티셔닝

#### 파티션 프루닝 (Partition Pruning)

**개념**: WHERE 절 조건으로 불필요한 파티션 스캔 제거

```sql
-- 월별 파티션 테이블
CREATE TABLE logs (
  id BIGSERIAL,
  created_at TIMESTAMPTZ,
  message TEXT
) PARTITION BY RANGE (created_at);

CREATE TABLE logs_2024_01 PARTITION OF logs
  FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
CREATE TABLE logs_2024_02 PARTITION OF logs
  FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');
-- ... 12개 파티션

-- 쿼리
SELECT * FROM logs
WHERE created_at >= '2024-01-15' AND created_at < '2024-01-20';
```

**실행 계획**:
```
Append
  ->  Seq Scan on logs_2024_01
        Filter: (created_at >= '2024-01-15' AND created_at < '2024-01-20')
-- logs_2024_02 ~ logs_2024_12는 스캔하지 않음 (프루닝됨)
```

**효과**: 12개 파티션 중 1개만 스캔 → **12배 빠름**

---

### 6. 병렬 쿼리

#### 병렬 실행 활성화

```sql
-- postgresql.conf
max_parallel_workers_per_gather = 4  -- 쿼리당 최대 4개 워커
max_parallel_workers = 8             -- 전체 시스템 최대 8개
max_worker_processes = 8             -- 백그라운드 프로세스 풀 크기

-- 동적 설정
SET max_parallel_workers_per_gather = 4;
```

**언제 병렬화?**
- 대용량 테이블 Seq Scan
- 집계 쿼리 (SUM, AVG, COUNT)
- 조인

**예시**:
```sql
EXPLAIN ANALYZE
SELECT COUNT(*), AVG(amount)
FROM large_table
WHERE created_at > '2023-01-01';
```

**실행 계획** (병렬):
```
Finalize Aggregate (actual time=1234.56)
  ->  Gather (workers=4, actual time=1234.12)
        ->  Partial Aggregate (actual time=1230.45)
              ->  Parallel Seq Scan on large_table
                    (rows=25000000, actual time=1100.23)
```

**효과**: 단일 스캔 5000ms → 병렬 스캔 1234ms (4배 빠름)

**주의**:
- 작은 테이블은 오히려 느려짐 (워커 생성 오버헤드)
- 병렬화는 리소스 집약적 (CPU, 메모리)

---

### 7. 복제를 통한 읽기 분산

#### Primary-Replica 아키텍처

```
┌──────────────┐
│ Application  │
└──────┬───────┘
       │
       ├─────> Primary (쓰기)
       │
       ├─────> Replica 1 (읽기)
       ├─────> Replica 2 (읽기)
       └─────> Replica 3 (읽기)
```

**스트리밍 복제 설정**:

**Primary (postgresql.conf)**:
```sql
wal_level = replica
max_wal_senders = 10
wal_keep_size = 1GB
```

**Replica**:
```bash
# Replica 초기화
pg_basebackup -h primary-host -D /data/replica -U replication -P -v -R

# postgresql.conf
hot_standby = on
```

**효과**:
- 읽기 처리량 수평 확장 (Replica 추가로 처리량 증가)
- Primary는 쓰기에만 집중 → 쓰기 성능 향상

#### 비동기 복제

```sql
-- Primary
synchronous_commit = local  -- Replica 복제 대기하지 않음
```

**이유**:
- 읽기는 약간의 지연 허용 가능 (수 초)
- 쓰기 성능 우선

**복제 지연 모니터링**:
```sql
-- Replica에서 실행
SELECT
  pg_last_wal_receive_lsn() - pg_last_wal_replay_lsn() AS lag_bytes,
  EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp())) AS lag_seconds;
```

---

## 읽기/쓰기 혼합 워크로드 최적화

### 1. 워크로드 특성 분석

#### 읽기:쓰기 비율 측정

```sql
SELECT
  datname,
  tup_fetched AS reads,
  tup_inserted + tup_updated + tup_deleted AS writes,
  ROUND(100.0 * tup_fetched /
    NULLIF(tup_fetched + tup_inserted + tup_updated + tup_deleted, 0), 2)
    AS read_percentage
FROM pg_stat_database
WHERE datname = current_database();
```

**결과 예시**:
```
 datname | reads  | writes | read_percentage
---------+--------+--------+----------------
 mydb    | 800000 | 200000 | 80.00
```
→ 읽기 80%, 쓰기 20% 워크로드

**최적화 전략 선택**:
- 읽기 > 80%: 읽기 최적화 우선
- 쓰기 > 80%: 쓰기 최적화 우선
- 혼합 (40-60%): 균형 전략

---

### 2. 균형잡힌 격리 수준

#### Repeatable Read를 기본으로

**왜?**
- 읽기: 일관성 보장
- 쓰기: 성능 수용 가능 (Read Committed보다 약간 느리지만 괜찮음)
- PostgreSQL 커뮤니티 권장

```sql
-- 데이터베이스 기본값 설정
ALTER DATABASE mydb SET default_transaction_isolation = 'repeatable read';
```

#### 쿼리 타입별 격리 수준

```python
# 읽기 전용 쿼리: Read Committed
def read_products():
    cur.execute("BEGIN")
    cur.execute("SET TRANSACTION ISOLATION LEVEL READ COMMITTED READ ONLY")
    cur.execute("SELECT * FROM products WHERE category = %s", (category,))
    products = cur.fetchall()
    cur.execute("COMMIT")
    return products

# 중요한 쓰기: Repeatable Read
def create_order(user_id, items):
    cur.execute("BEGIN")
    cur.execute("SET TRANSACTION ISOLATION LEVEL REPEATABLE READ")

    # 재고 확인 및 주문 생성
    cur.execute("SELECT stock FROM products WHERE id = %s FOR UPDATE", (product_id,))
    stock = cur.fetchone()[0]

    if stock >= quantity:
        cur.execute("UPDATE products SET stock = stock - %s WHERE id = %s",
                   (quantity, product_id))
        cur.execute("INSERT INTO orders (user_id, product_id, quantity) VALUES (%s, %s, %s)",
                   (user_id, product_id, quantity))
        cur.execute("COMMIT")
        return True
    else:
        cur.execute("ROLLBACK")
        return False
```

---

### 3. 인덱스 밸런싱

#### 선택적 인덱싱 전략

**원칙**:
1. **읽기 집약적 테이블**: 필요한 인덱스 모두 생성
2. **쓰기 집약적 테이블**: 필수 인덱스만 (PK + 자주 쿼리되는 컬럼)
3. **혼합 테이블**: 쿼리 패턴 분석 후 선택적 생성

**예시** (E-commerce):
```sql
-- 상품 테이블 (읽기 집약: 조회 많음, 변경 적음)
CREATE INDEX idx_products_category ON products(category);
CREATE INDEX idx_products_price ON products(price);
CREATE INDEX idx_products_name ON products(name);  -- 검색용
CREATE INDEX idx_products_created ON products(created_at);

-- 주문 테이블 (쓰기 집약: 계속 생성됨)
-- PK만 유지, 다른 인덱스는 최소화
CREATE INDEX idx_orders_user ON orders(user_id);  -- 필수 (사용자별 조회)
-- idx_orders_created는 생성하지 않음 (파티셔닝으로 대체)
```

#### 인덱스 사용률 모니터링

```sql
SELECT
  schemaname,
  tablename,
  indexname,
  idx_scan,
  idx_tup_read,
  idx_tup_fetch,
  pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
FROM pg_stat_user_indexes
ORDER BY idx_scan ASC
LIMIT 20;
```

**판단 기준**:
- `idx_scan = 0` → 사용되지 않는 인덱스 → 제거 검토
- `idx_scan < 100` & 큰 크기 → 비효율적 인덱스

---

### 4. Primary-Replica 분리 아키텍처

#### 아키텍처 패턴

```
┌──────────────────┐
│   Application    │
│   ┌──────────┐   │
│   │ DB Router│   │
│   └─────┬────┘   │
│         │        │
│    ┌────┴─────┐  │
│    │          │  │
└────┼──────────┼──┘
     │          │
     ▼          ▼
┌─────────┐  ┌─────────┐
│ Primary │  │Replica 1│
│ (쓰기)  │──>│ (읽기)  │
└─────────┘  └─────────┘
     │       ┌─────────┐
     └──────>│Replica 2│
             │ (읽기)  │
             └─────────┘
```

**라우팅 로직** (Python):
```python
import psycopg2

# 연결 풀
primary_conn = psycopg2.connect("host=primary dbname=mydb")
replica_conns = [
    psycopg2.connect("host=replica1 dbname=mydb"),
    psycopg2.connect("host=replica2 dbname=mydb"),
]

def execute_write(query, params):
    """쓰기는 Primary로"""
    cur = primary_conn.cursor()
    cur.execute(query, params)
    primary_conn.commit()

def execute_read(query, params):
    """읽기는 Replica로 (라운드 로빈)"""
    replica = random.choice(replica_conns)
    cur = replica.cursor()
    cur.execute(query, params)
    return cur.fetchall()

# 사용
execute_write("INSERT INTO orders ...", (...))
products = execute_read("SELECT * FROM products WHERE ...", (...))
```

**효과**:
- Primary: 쓰기에만 집중 → 쓰기 성능 향상
- Replica: 읽기 부하 분산 → 읽기 처리량 증가

---

### 5. 하드웨어 리소스 배분

#### CPU

```sql
-- postgresql.conf
max_worker_processes = 16           -- 전체 백그라운드 워커

# 읽기 (병렬 쿼리)
max_parallel_workers = 8
max_parallel_workers_per_gather = 4

# 쓰기 (VACUUM, 인덱스)
autovacuum_max_workers = 3
max_wal_senders = 3                 -- 복제
```

**배분 예시** (16 CPU 코어):
- PostgreSQL 백엔드: 8-12 코어
- 병렬 쿼리 워커: 최대 8 코어
- Autovacuum: 3 코어
- 시스템: 4 코어

#### 메모리

```sql
-- postgresql.conf
shared_buffers = 8GB               -- 읽기 캐시 (RAM 25%)
work_mem = 64MB                    -- 정렬, 해시 조인 (읽기)
maintenance_work_mem = 2GB         -- VACUUM, 인덱스 생성 (쓰기 관련)

effective_cache_size = 24GB        -- OS 캐시 힌트 (RAM 75%)
```

**설명**:
- **shared_buffers**: 데이터 페이지 캐싱 (읽기 성능)
- **work_mem**: 복잡한 쿼리 처리 (읽기 성능)
- **maintenance_work_mem**: VACUUM, 인덱스 생성 (쓰기 유지보수)

---

### 6. 모니터링 및 동적 조정

#### 핵심 지표 추적

```sql
-- 1. 쿼리별 성능 (pg_stat_statements 확장 필요)
CREATE EXTENSION pg_stat_statements;

SELECT
  query,
  calls,
  total_exec_time / 1000 AS total_seconds,
  mean_exec_time AS avg_ms,
  max_exec_time AS max_ms
FROM pg_stat_statements
ORDER BY total_exec_time DESC
LIMIT 10;

-- 2. 데이터베이스 통계
SELECT
  datname,
  xact_commit,
  xact_rollback,
  blks_read,    -- 디스크 읽기
  blks_hit,     -- 캐시 히트
  tup_returned, -- 읽기
  tup_inserted + tup_updated + tup_deleted AS writes
FROM pg_stat_database;

-- 3. 체크포인트 성능
SELECT
  checkpoints_timed,
  checkpoints_req,
  checkpoint_write_time,
  checkpoint_sync_time
FROM pg_stat_bgwriter;

-- 4. 복제 지연
SELECT
  client_addr,
  state,
  sent_lsn,
  write_lsn,
  flush_lsn,
  replay_lsn,
  sync_state
FROM pg_stat_replication;
```

#### 동적 조정 사례

**사례**: 읽기 비율이 80% → 90%로 증가

**조정**:
```sql
-- 병렬 쿼리 워커 증가
ALTER SYSTEM SET max_parallel_workers_per_gather = 6;  -- 4 → 6

-- 공유 버퍼 증가 (재시작 필요)
ALTER SYSTEM SET shared_buffers = '12GB';  -- 8GB → 12GB

-- 설정 재로드
SELECT pg_reload_conf();
```

---

## 실전 시나리오 및 벤치마크

### 시나리오 1: 로그 수집 시스템 (쓰기 집약)

#### 요구사항
- 초당 **100,000 건의 로그** INSERT
- 로그 보존: 30일
- 쿼리: 최근 24시간 로그 조회, 에러 로그 필터링

#### 최적화 전략

**1. 격리 수준**:
```sql
-- Read Committed (기본값)
-- 별도 설정 불필요
```

**2. 배치 INSERT + COPY**:
```python
# Batch buffering (1초마다 flush)
buffer = []
last_flush = time.time()

def insert_log(log_entry):
    buffer.append(log_entry)

    if time.time() - last_flush > 1.0:
        flush_logs()

def flush_logs():
    cur.copy_from(
        StringIO('\n'.join(buffer)),
        'logs',
        columns=('timestamp', 'level', 'message')
    )
    conn.commit()
    buffer.clear()
```

**3. 시간 기반 파티셔닝**:
```sql
CREATE TABLE logs (
  id BIGSERIAL,
  timestamp TIMESTAMPTZ NOT NULL,
  level VARCHAR(10),
  message TEXT
) PARTITION BY RANGE (timestamp);

-- 일별 파티션 (cron으로 자동 생성)
CREATE TABLE logs_2024_01_18 PARTITION OF logs
  FOR VALUES FROM ('2024-01-18') TO ('2024-01-19');
```

**4. 인덱스 최소화**:
```sql
-- timestamp 인덱스만 (BRIN으로 공간 절약)
CREATE INDEX idx_logs_timestamp ON logs USING brin(timestamp);

-- level 인덱스는 부분 인덱스로
CREATE INDEX idx_logs_error ON logs(timestamp)
  WHERE level = 'ERROR';
```

**5. WAL 설정**:
```sql
-- postgresql.conf
synchronous_commit = off  -- 로그 손실 허용
wal_buffers = 32MB
```

**6. 공격적인 Autovacuum**:
```sql
ALTER TABLE logs SET (
  autovacuum_vacuum_scale_factor = 0.01,  -- 1% 변경 시 VACUUM
  autovacuum_vacuum_threshold = 5000
);
```

**7. 파티션 자동 삭제**:
```sql
-- 30일 이상 된 파티션 삭제 (cron)
DROP TABLE IF EXISTS logs_2023_12_19;
```

#### 예상 결과

| 지표 | 값 |
|-----|---|
| **처리량** | 100,000 TPS |
| **평균 지연** | < 1ms |
| **디스크 사용량** | 안정적 (30일 데이터만 유지) |
| **CPU 사용률** | 40-60% |

---

### 시나리오 2: 분석 대시보드 (읽기 집약)

#### 요구사항
- 복잡한 집계 쿼리 (SUM, AVG, GROUP BY)
- 응답 시간: **< 500ms**
- 동시 사용자: 1000+
- 데이터: 수억 rows

#### 최적화 전략

**1. Materialized View**:
```sql
-- 일별 판매 집계 (사전 계산)
CREATE MATERIALIZED VIEW daily_sales AS
SELECT
  DATE_TRUNC('day', created_at) AS day,
  product_id,
  COUNT(*) AS order_count,
  SUM(amount) AS total_sales,
  AVG(amount) AS avg_sales
FROM orders
GROUP BY DATE_TRUNC('day', created_at), product_id;

-- 인덱스
CREATE INDEX idx_daily_sales_day ON daily_sales(day);
CREATE INDEX idx_daily_sales_product ON daily_sales(product_id);

-- 정기 갱신 (매시간)
REFRESH MATERIALIZED VIEW CONCURRENTLY daily_sales;
```

**2. 적절한 인덱스**:
```sql
-- 복합 인덱스 (자주 함께 쿼리되는 컬럼)
CREATE INDEX idx_orders_date_product ON orders(created_at, product_id);

-- 커버링 인덱스
CREATE INDEX idx_orders_summary ON orders(created_at, product_id)
  INCLUDE (amount, quantity);
```

**3. 병렬 쿼리**:
```sql
SET max_parallel_workers_per_gather = 4;

SELECT
  product_id,
  SUM(amount) AS total,
  COUNT(*) AS count
FROM orders
WHERE created_at >= '2024-01-01'
GROUP BY product_id;
-- 병렬 실행으로 4배 빠름
```

**4. 읽기 전용 복제본**:
```
Application → Load Balancer
              ├─> Replica 1 (읽기)
              ├─> Replica 2 (읽기)
              └─> Replica 3 (읽기)
```

**5. 연결 풀링**:
```ini
# PgBouncer
pool_mode = transaction
max_client_conn = 5000
default_pool_size = 100
```

#### 예상 결과

| 지표 | 값 |
|-----|---|
| **쿼리 응답 시간** | 200-400ms (P95) |
| **동시 사용자** | 1000+ |
| **처리량** | 10,000 QPS |
| **캐시 히트율** | > 95% |

---

### 시나리오 3: E-commerce 플랫폼 (혼합)

#### 요구사항
- 주문 처리 (쓰기): 30%
- 상품 조회 (읽기): 70%
- 일관성 중요: 재고 관리
- P95 응답 시간: < 100ms

#### 최적화 전략

**1. Repeatable Read 기본**:
```python
# 주문 생성 (일관성 중요)
def create_order(user_id, items):
    cur.execute("BEGIN")
    cur.execute("SET TRANSACTION ISOLATION LEVEL REPEATABLE READ")

    for item in items:
        # 재고 확인 및 차감
        cur.execute("SELECT stock FROM products WHERE id = %s FOR UPDATE",
                   (item['product_id'],))
        stock = cur.fetchone()[0]

        if stock >= item['quantity']:
            cur.execute("UPDATE products SET stock = stock - %s WHERE id = %s",
                       (item['quantity'], item['product_id']))
        else:
            cur.execute("ROLLBACK")
            raise InsufficientStock()

    cur.execute("INSERT INTO orders (...) VALUES (...)")
    cur.execute("COMMIT")
```

**2. Primary-Replica 아키텍처**:
```python
# 쓰기 → Primary
def write_query(query, params):
    return primary_conn.execute(query, params)

# 읽기 → Replica
def read_query(query, params):
    replica = select_replica()  # 로드 밸런싱
    return replica.execute(query, params)

# 사용
write_query("INSERT INTO orders ...", (...))
products = read_query("SELECT * FROM products ...", (...))
```

**3. 선택적 인덱싱**:
```sql
-- 주문 테이블 (쓰기 집약)
CREATE INDEX idx_orders_user ON orders(user_id);  -- 필수만
-- created_at 인덱스는 파티셔닝으로 대체

-- 상품 테이블 (읽기 집약)
CREATE INDEX idx_products_category ON products(category);
CREATE INDEX idx_products_name ON products USING gin(to_tsvector('english', name));
CREATE INDEX idx_products_price ON products(price);
```

**4. Redis 캐싱 (상품 정보)**:
```python
def get_product(product_id):
    # Redis 캐시 확인
    cached = redis_client.get(f"product:{product_id}")
    if cached:
        return json.loads(cached)

    # DB 조회 (Replica)
    product = read_query("SELECT * FROM products WHERE id = %s", (product_id,))

    # 캐싱 (TTL 10분)
    redis_client.setex(f"product:{product_id}", 600, json.dumps(product))
    return product
```

**5. 연결 풀링**:
```ini
# PgBouncer (Session 모드)
pool_mode = session  # Prepared statements 지원
max_client_conn = 2000
default_pool_size = 50
```

#### 예상 결과

| 지표 | 쓰기 | 읽기 |
|-----|-----|-----|
| **처리량** | 5,000 TPS | 15,000 QPS |
| **P95 지연** | 80ms | 50ms |
| **캐시 히트율** | - | 85% |
| **Replica 지연** | - | < 100ms |

---

## 성능 측정 및 벤치마킹

### 벤치마크 도구

#### pgbench (기본 도구)

**설치 및 초기화**:
```bash
# 테스트 DB 초기화
pgbench -i -s 50 mydb
# -s 50: 스케일 팩터 (약 7.5GB 데이터)

# 벤치마크 실행
pgbench -c 10 -j 2 -t 1000 mydb
# -c 10: 10개 동시 연결
# -j 2: 2개 스레드
# -t 1000: 클라이언트당 1000 트랜잭션
```

**커스텀 스크립트**:
```sql
-- custom_benchmark.sql
\set user_id random(1, 100000)
BEGIN;
SELECT * FROM users WHERE id = :user_id;
INSERT INTO logs (user_id, action) VALUES (:user_id, 'login');
COMMIT;
```

```bash
pgbench -c 50 -j 4 -T 60 -f custom_benchmark.sql mydb
# -T 60: 60초 동안 실행
```

**결과 해석**:
```
transaction type: <builtin: TPC-B (sort of)>
scaling factor: 50
query mode: simple
number of clients: 10
number of threads: 2
number of transactions per client: 1000
number of transactions actually processed: 10000/10000
latency average = 12.345 ms
tps = 809.876543 (including connections establishing)
tps = 810.123456 (excluding connections establishing)
```

---

### 주요 성능 지표

#### 1. 처리량 (Throughput)

- **TPS (Transactions Per Second)**: 쓰기 성능
- **QPS (Queries Per Second)**: 읽기 성능

**측정**:
```sql
-- 현재 TPS
SELECT
  xact_commit + xact_rollback AS total_txns,
  (xact_commit + xact_rollback) /
    EXTRACT(EPOCH FROM (now() - stats_reset)) AS tps
FROM pg_stat_database
WHERE datname = current_database();
```

#### 2. 지연시간 (Latency)

- **평균 (Average)**: 전체 평균
- **P50 (Median)**: 중간값
- **P95**: 상위 5%의 느린 요청
- **P99**: 상위 1%의 느린 요청 (테일 레이턴시)

**측정** (pg_stat_statements):
```sql
SELECT
  query,
  calls,
  mean_exec_time AS avg_ms,
  max_exec_time AS max_ms,
  percentile_cont(0.50) WITHIN GROUP (ORDER BY mean_exec_time) AS p50,
  percentile_cont(0.95) WITHIN GROUP (ORDER BY mean_exec_time) AS p95,
  percentile_cont(0.99) WITHIN GROUP (ORDER BY mean_exec_time) AS p99
FROM pg_stat_statements
GROUP BY query, calls, mean_exec_time, max_exec_time;
```

#### 3. 리소스 사용률

**CPU**:
```bash
top -p $(pgrep -d',' postgres)
```

**메모리**:
```sql
SELECT
  sum(heap_blks_read) AS heap_read,
  sum(heap_blks_hit) AS heap_hit,
  sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read)) AS cache_hit_ratio
FROM pg_statio_user_tables;
```

**I/O**:
```bash
iostat -x 1
```

---

## 체크리스트 및 빠른 참조

### 고성능 쓰기 체크리스트

- [ ] **격리 수준**: Read Committed 사용
- [ ] **배치 처리**: COPY 또는 다중 행 INSERT
- [ ] **인덱스 최소화**: 필수 인덱스만 유지
- [ ] **synchronous_commit**: `off` 검토 (데이터 손실 허용 시)
- [ ] **Autovacuum**: 공격적인 설정 (scale_factor = 0.05)
- [ ] **연결 풀링**: PgBouncer Transaction 모드
- [ ] **하드웨어**: SSD (NVMe 선호)
- [ ] **WAL 분리**: 별도 디스크에 저장
- [ ] **파티셔닝**: 시간 기반 파티셔닝 (로그, 시계열)

### 고성능 읽기 체크리스트

- [ ] **인덱스 생성**: B-tree, GIN, BRIN 적절히 활용
- [ ] **커버링 인덱스**: INCLUDE 절 사용
- [ ] **EXPLAIN ANALYZE**: 쿼리 최적화
- [ ] **Materialized View**: 복잡한 집계 사전 계산
- [ ] **병렬 쿼리**: max_parallel_workers_per_gather 설정
- [ ] **읽기 전용 복제본**: Primary-Replica 분리
- [ ] **애플리케이션 캐싱**: Redis, Memcached
- [ ] **shared_buffers**: RAM의 25% 할당
- [ ] **파티셔닝**: 파티션 프루닝 활용

### 혼합 워크로드 체크리스트

- [ ] **Repeatable Read**: 기본 격리 수준
- [ ] **Primary-Replica 분리**: 쓰기/읽기 분리
- [ ] **선택적 인덱싱**: 쓰기 테이블은 최소화
- [ ] **워크로드 프로파일링**: pg_stat_database 모니터링
- [ ] **연결 풀링**: PgBouncer Session 모드
- [ ] **모니터링**: pg_stat_statements, pg_stat_bgwriter
- [ ] **동적 조정**: 워크로드 변화에 맞춰 튜닝
- [ ] **복제 지연 모니터링**: Replica lag 추적

---

## FAQ

### Q1: 쓰기 성능과 읽기 성능 중 하나를 선택해야 한다면?

**A**: **비즈니스 요구사항**에 따라 결정합니다.

**일반적인 원칙**:
- **쓰기 우선**: 데이터 손실은 치명적 (금융, 주문, 사용자 계정)
- **읽기 우선**: 사용자 경험 중시 (소셜 미디어 피드, 검색)

**해결 방법**:
- 읽기는 **캐싱, 복제**로 해결 가능 (수평 확장)
- 쓰기는 수평 확장 어려움 (샤딩 필요) → 최적화가 더 중요

**권장**: 쓰기 최적화 우선 + 읽기 복제본으로 읽기 확장

---

### Q2: synchronous_commit = off는 안전한가?

**A**: **데이터 손실을 허용할 수 있는 경우에만** 사용하세요.

**안전한 경우**:
- ✅ 로그 수집 (일부 손실 허용)
- ✅ 메트릭, 분석 데이터 (재생성 가능)
- ✅ 캐시, 세션 데이터 (임시 데이터)

**위험한 경우**:
- ❌ 금융 거래 (절대 불가)
- ❌ 사용자 계정 정보 (복구 불가)
- ❌ 주문, 결제 (비즈니스 크리티컬)

**손실 범위**: 크래시 시 최근 **수 초**의 트랜잭션 손실 가능

**대안**: `synchronous_commit = local` (로컬은 안전, 복제만 비동기)

---

### Q3: 언제 Serializable을 사용해야 하나?

**A**: **완벽한 일관성이 필수**이고 **성능보다 정확성이 우선**일 때만 사용하세요.

**사용 사례**:
- 금융 거래 (이중 지출 방지)
- 재고 관리 (동시 구매 시 재고 초과 방지)
- 회계 시스템 (복식 부기 일관성)

**비용**:
- 처리량 40-50% 감소
- 재시도율 5-15%
- 애플리케이션 재시도 로직 필수

**대안**:
- 대부분의 경우: **Repeatable Read + SELECT FOR UPDATE**로 충분

---

### Q4: 인덱스는 많을수록 좋은가?

**A**: **아니요!** 각 인덱스는 쓰기 시 추가 비용을 발생시킵니다.

**원칙**:
1. **실제 쿼리 패턴 분석**: `pg_stat_user_indexes`로 사용률 확인
2. **필수 인덱스만 유지**: PK + 자주 쿼리되는 컬럼
3. **사용되지 않는 인덱스 제거**: `idx_scan = 0` 인덱스 삭제

**벤치마크**:
```
인덱스 0개: 10,000 TPS
인덱스 5개:  5,000 TPS (50% 감소!)
```

**트레이드오프**: 읽기 성능 vs 쓰기 성능

---

### Q5: autovacuum을 비활성화하면 성능이 향상되나?

**A**: **절대 비활성화하지 마세요!**

**단기적 (1-2일)**:
- ✅ 쓰기 성능 약간 향상 (VACUUM CPU 사용 제거)

**장기적 (1주일+)**:
- ❌ Table bloat 급증 → 테이블 크기 10배 증가
- ❌ 읽기/쓰기 모두 급격히 느려짐
- ❌ 인덱스 bloat → 인덱스 스캔 느려짐
- ❌ XID wraparound 위험 → 데이터베이스 셧다운

**올바른 방법**: autovacuum 설정 **튜닝** (비활성화 X)

---

### Q6: 파티셔닝은 언제 사용해야 하나?

**A**: **대용량 테이블** (수억 rows) & **시간 기반 쿼리**일 때 효과적입니다.

**적합한 경우**:
- 로그 테이블 (일별/월별 파티션)
- 시계열 데이터 (센서, 메트릭)
- 오래된 데이터 삭제 필요 (GDPR 등)

**효과**:
- 파티션 프루닝 → 쿼리 속도 10-100배 향상
- 오래된 파티션 DROP → 빠른 삭제 (DELETE보다)
- 인덱스 크기 감소 → 쓰기 성능 향상

**부적합한 경우**:
- 작은 테이블 (< 수백만 rows)
- 시간 기반이 아닌 쿼리 (user_id 등)

---

### Q7: 병렬 쿼리는 항상 빠른가?

**A**: **아니요!** 큰 테이블 스캔에만 효과적입니다.

**효과적인 경우**:
- 대용량 테이블 Seq Scan (수천만 rows)
- 집계 쿼리 (SUM, AVG, COUNT)
- 복잡한 조인

**비효율적인 경우**:
- 작은 테이블 (워커 생성 오버헤드 > 성능 향상)
- 인덱스 스캔 (이미 빠름)

**벤치마크**:
```
소형 테이블 (10만 rows):
  - 단일: 100ms
  - 병렬: 150ms (오히려 느림!)

대형 테이블 (1억 rows):
  - 단일: 5000ms
  - 병렬 (4 워커): 1250ms (4배 빠름!)
```

---

## 참고 자료 및 추가 학습

### 공식 문서
- [PostgreSQL Performance Tips](https://www.postgresql.org/docs/current/performance-tips.html)
- [Tuning PostgreSQL](https://wiki.postgresql.org/wiki/Tuning_Your_PostgreSQL_Server)
- [pg_stat_statements](https://www.postgresql.org/docs/current/pgstatstatements.html)

### 내부 문서
- [MVCC_Guide.md](/postgresql/MVCC_Guide.md): MVCC 기본 이해
- [트랜잭션_격리수준_스냅샷.md](/postgresql/트랜잭션_격리수준_스냅샷.md): 격리 수준과 스냅샷

### 도구
- **PgBouncer**: 연결 풀링 - [pgbouncer.org](https://www.pgbouncer.org/)
- **pgbench**: 벤치마킹 도구
- **pg_stat_statements**: 쿼리 성능 분석
- **pgAdmin**: GUI 관리 도구

### 추가 학습
- Bruce Momjian의 PostgreSQL 성능 프레젠테이션
- [Use The Index, Luke!](https://use-the-index-luke.com/) - 인덱스 최적화 가이드
- [Awesome PostgreSQL Performance](https://github.com/dhamaniasad/awesome-postgres#performance)

---

## 요약

### 핵심 원칙

1. **워크로드 특성 파악**: 읽기/쓰기 비율 측정 → 맞춤 최적화
2. **측정 기반 최적화**: EXPLAIN ANALYZE, pg_stat_statements 활용
3. **트레이드오프 이해**: 쓰기 최적화 ↔ 읽기 최적화
4. **MVCC 특성 활용**: 높은 동시성, VACUUM 관리 중요
5. **하드웨어 중요**: SSD, 충분한 메모리는 모든 최적화의 기본

### 빠른 의사결정 트리

```
워크로드 타입?
│
├─ 쓰기 > 80%
│  → Read Committed, COPY, 인덱스 최소화, synchronous_commit=off
│
├─ 읽기 > 80%
│  → 인덱스 최적화, Materialized View, 복제본, 병렬 쿼리
│
└─ 혼합 (40-60%)
   → Repeatable Read, Primary-Replica 분리, 선택적 인덱싱
```

**성공적인 최적화는 측정에서 시작합니다!**

---

*이 문서는 PostgreSQL 16 기준으로 작성되었습니다. (2024년 1월)*
